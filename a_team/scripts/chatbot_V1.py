import os
import warnings
from pathlib import Path
from typing import Annotated, TypedDict, Sequence
from dotenv import load_dotenv

# Qdrant & LangChain ê´€ë ¨ ì„í¬íŠ¸
from qdrant_client import QdrantClient
from langchain_qdrant import QdrantVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_openai import ChatOpenAI

# LangGraph ê´€ë ¨ ì„í¬íŠ¸
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ: ì‹¤í–‰ ìœ„ì¹˜(CWD)ì™€ ë¬´ê´€í•˜ê²Œ ì´ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì˜ .envë¥¼ ì‚¬ìš©
_DOTENV_PATH = Path(__file__).with_name(".env")
load_dotenv(dotenv_path=_DOTENV_PATH)


# ===========================
# State ì •ì˜
# ===========================
class AgentState(TypedDict):
    """LangGraph Agentì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” TypedDict"""
    # messages: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìë™ìœ¼ë¡œ ì¶”ê°€ë¨)
    messages: Annotated[Sequence[BaseMessage], add_messages]


# ===========================
# Tool ì •ì˜
# ===========================
def create_legal_search_tool(vectorstore: QdrantVectorStore):
    """ë²•ë¥  ê²€ìƒ‰ Tool ìƒì„±"""
    
    @tool("legal_search_tool")
    def legal_search_tool(query: str) -> str:
        """ë²•ë¥ /íŒë¡€/í–‰ì •í•´ì„ì„ Qdrantì—ì„œ ê²€ìƒ‰í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        k = 5  # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
        max_chars = 1200  # ë¬¸ì„œë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜
        
        results = vectorstore.similarity_search_with_score(query, k=k)
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”."
        
        lines = []
        for i, (doc, score) in enumerate(results, start=1):
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = doc.metadata
            source = metadata.get("source", "unknown")
            title = metadata.get("title", "")
            chunk_info = f"ì²­í¬ {metadata.get('chunk_index', 0)+1}/{metadata.get('total_chunks', 1)}"
            
            lines.append(f"[ë¬¸ì„œ {i}] score={score:.4f} | {source} | {title} | {chunk_info}")
            
            content = (doc.page_content or "").strip()
            if content:
                if max_chars > 0 and len(content) > max_chars:
                    content = content[:max_chars].rstrip() + "â€¦"
                lines.append(content)
            else:
                lines.append("(ë³¸ë¬¸ ì—†ìŒ)")
            lines.append("")
        
        return "\n".join(lines).strip()
    
    return legal_search_tool


# ===========================
# ê·¸ë˜í”„ ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
# ===========================
def create_agent_node(llm_with_tools):
    """Agent ë…¸ë“œ: LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ì— ì‘ë‹µí•˜ê±°ë‚˜ Toolì„ í˜¸ì¶œ"""
    def agent_node(state: AgentState) -> AgentState:
        messages = state["messages"]
        response = llm_with_tools.invoke(messages)
        return {"messages": [response]}
    return agent_node


def should_continue(state: AgentState) -> str:
    """ì¡°ê±´ë¶€ ì—£ì§€: Tool í˜¸ì¶œì´ ìˆìœ¼ë©´ 'tools'ë¡œ, ì—†ìœ¼ë©´ 'end'ë¡œ ë¼ìš°íŒ…"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # Tool callsê°€ ìˆìœ¼ë©´ tools ë…¸ë“œë¡œ ì´ë™
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    # ì—†ìœ¼ë©´ ì¢…ë£Œ
    return "end"


# ===========================
# LangGraph ì´ˆê¸°í™”
# ===========================
def initialize_langgraph_chatbot():
    """LangGraph ê¸°ë°˜ RAG ì±—ë´‡ ì´ˆê¸°í™”"""
    
    # 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME")
    QDRANT_URL = os.getenv("QDRANT_URL")
    QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
    
    if not QDRANT_API_KEY:
        raise ValueError("QDRANT_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    
    print(f"ğŸ”§ ì„¤ì • ë¡œë“œ ì™„ë£Œ")
    
    # 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    print(f"\nğŸš€ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ (Qwen/Qwen3-Embedding-0.6B)...")
    embeddings = HuggingFaceEmbeddings(
        model_name="Qwen/Qwen3-Embedding-0.6B",
        model_kwargs={'trust_remote_code': True},
        encode_kwargs={'normalize_embeddings': True}
    )
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 3. Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    print(f"\nğŸ“¡ Qdrant ì—°ê²° ì¤‘...")
    warnings.filterwarnings(
        'ignore', message='Api key is used with an insecure connection')
    
    client = QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
        timeout=30,
        prefer_grpc=False)
    print("âœ… Qdrant ì—°ê²° ì™„ë£Œ")
    
    # 4. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    print(f"\nğŸ—‚ï¸  ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")
    print("   (ì»¬ë ‰ì…˜ ê²€ì¦ ì¤‘... ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    vectorstore = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
        embedding=embeddings,
        content_payload_key="text"
    )
    print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # 5. Tool ìƒì„±
    print(f"\nğŸ› ï¸  Tool ìƒì„± ì¤‘...")
    legal_tool = create_legal_search_tool(vectorstore)
    tools = [legal_tool]
    print("âœ… Tool ìƒì„± ì™„ë£Œ")
    
    # 6. LLM ì„¤ì •
    print(f"\nğŸ¤– LLM ì„¤ì • ì¤‘...")
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0,
        streaming=True
    )
    
    # Toolì„ LLMì— ë°”ì¸ë”©
    llm_with_tools = llm.bind_tools(tools)
    print("âœ… LLM ì„¤ì • ì™„ë£Œ")
    
    # 7. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    system_prompt = """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ 'A-TEAM ë´‡'ì…ë‹ˆë‹¤.

ì—­í• :
- ì‚¬ìš©ìì˜ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- legal_search_toolì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ê²€ìƒ‰ëœ ë²•ë ¹, íŒë¡€, í–‰ì •í•´ì„ì„ ë°”íƒ•ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

ë‹µë³€ ì›ì¹™:
1. ê²€ìƒ‰ëœ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë²•ë ¹ëª…, ì¡°í•­, íŒë¡€ë²ˆí˜¸ ë“± êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
3. ë²•ë¥  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
4. í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ê²€ìƒ‰ ë„êµ¬ë¥¼ í™œìš©í•˜ì„¸ìš”.
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
    
    # 8. LangGraph ìƒì„±
    print(f"\nâš™ï¸  LangGraph êµ¬ì„± ì¤‘...")
    
    # StateGraph ì´ˆê¸°í™”
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    agent_node_func = create_agent_node(llm_with_tools)
    workflow.add_node("agent", agent_node_func)
    workflow.add_node("tools", ToolNode(tools))
    
    # ì—£ì§€ ì¶”ê°€
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "end": END
        }
    )
    workflow.add_edge("tools", "agent")
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    graph = workflow.compile()
    print("âœ… LangGraph êµ¬ì„± ì™„ë£Œ")
    
    return graph, system_prompt


# ===========================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===========================
def main():
    """LangGraph RAG ì±—ë´‡ ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜"""
    
    # API Key í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    try:
        # ì±—ë´‡ ì´ˆê¸°í™”
        print("\n" + "="*60)
        print("ğŸš€ A-TEAM ë²•ë¥  RAG ì±—ë´‡ (LangGraph) ì´ˆê¸°í™” ì‹œì‘")
        print("="*60 + "\n")
        
        graph, system_prompt = initialize_langgraph_chatbot()
        
        print("\n" + "="*60)
        print("âœ… ğŸ¤– A-TEAM ë²•ë¥  ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!")
        print("="*60)
        print("\nğŸ’¡ ì‚¬ìš© ë°©ë²•:")
        print("  - ë…¸ë™ë¶„ì•¼ ë²•ë¥ , í˜•ì‚¬ë²•, ë¯¼ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì— ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("  - 'exit', 'quit', 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤")
        print("="*60 + "\n")
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥ (ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
        messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        from langchain_core.messages import SystemMessage
        messages.append(SystemMessage(content=system_prompt))
        
        # ëŒ€í™” ë£¨í”„
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                user_input = input("ğŸ‘¤ User >> ").strip()
                
                # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
                if user_input.lower() in ["exit", "quit", "ì¢…ë£Œ", "q"]:
                    print("\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break
                
                # ë¹ˆ ì…ë ¥ ì²´í¬
                if not user_input:
                    print("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
                    continue
                
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                messages.append(HumanMessage(content=user_input))
                
                # ê·¸ë˜í”„ ì‹¤í–‰
                print()  # ì¤„ë°”ê¿ˆ
                result = graph.invoke({"messages": messages})
                
                # ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
                response_messages = result["messages"]
                ai_response = None
                
                # ë§ˆì§€ë§‰ AIMessage ì°¾ê¸°
                for msg in reversed(response_messages):
                    if isinstance(msg, AIMessage) and not msg.tool_calls:
                        ai_response = msg.content
                        break
                
                if ai_response:
                    print(f"\nğŸ¤– AI >> {ai_response}\n")
                    print("-" * 60 + "\n")
                    # ì „ì²´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                    messages = response_messages
                else:
                    print("\nâš ï¸ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")
    
    except Exception as e:
        print(f"\nâŒ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ì„¤ì •ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        raise


if __name__ == "__main__":
    main()
