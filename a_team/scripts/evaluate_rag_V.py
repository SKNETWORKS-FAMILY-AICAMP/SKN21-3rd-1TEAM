"""
ë…¸ë™ë²• RAG ì±—ë´‡ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (LangGraph V1 ë²„ì „)

Golden Datasetì„ ì‚¬ìš©í•˜ì—¬ LangGraph ê¸°ë°˜ RAG ëª¨ë¸(V1)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
Ragas ë©”íŠ¸ë¦­(Faithfulness, Answer Relevancy, Context Precision/Recall)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

Usage:
    # ê¸°ë³¸ ì‹¤í–‰
    uv run a_team/scripts/evaluate_rag_V1.py

    # ìƒ˜í”Œ ìˆ˜ ì§€ì • (í…ŒìŠ¤íŠ¸ìš©)
    uv run a_team/scripts/evaluate_rag_V1.py --sample 10

    # ì»¤ìŠ¤í…€ ê³¨ë“ ì…‹ ê²½ë¡œ
    uv run a_team/scripts/evaluate_rag_other.py --golden-set a_team/data/evaluation/golden_set_quota_20.json
"""

import os
import sys
import argparse
import warnings
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

import pandas as pd
from dotenv import load_dotenv
from tqdm import tqdm

# Ragas í‰ê°€ ë©”íŠ¸ë¦­
from ragas import evaluate
from ragas.metrics import (
    Faithfulness,
    ResponseRelevancy,
    LLMContextPrecisionWithoutReference,
    LLMContextRecall,
)
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.llms import LangchainLLMWrapper
from datasets import Dataset

# LangChain (í‰ê°€ìš© LLM)
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.messages import HumanMessage

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
_SCRIPT_DIR = Path(__file__).parent
load_dotenv(dotenv_path=_SCRIPT_DIR / ".env")

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings("ignore", category=DeprecationWarning)


# ============================================================
# Golden Dataset ë¡œë“œ
# ============================================================
def load_golden_dataset(path: str) -> pd.DataFrame:
    """
    Golden Dataset JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        path: JSON íŒŒì¼ ê²½ë¡œ

    Returns:
        DataFrame with columns: user_input, reference (ground truth)
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"Golden Datasetì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")

    df = pd.read_json(path)

    # Ragas 0.4.x ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
    # ì˜ˆìƒ ì»¬ëŸ¼: user_input, reference, reference_contexts
    required_cols = []

    # ì§ˆë¬¸ ì»¬ëŸ¼ ì°¾ê¸°
    question_col = None
    for col in ['user_input', 'question', 'query']:
        if col in df.columns:
            question_col = col
            break

    if question_col is None:
        raise ValueError(f"ì§ˆë¬¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {list(df.columns)}")

    # ì •ë‹µ ì»¬ëŸ¼ ì°¾ê¸°
    answer_col = None
    for col in ['reference', 'ground_truth', 'answer', 'expected_answer']:
        if col in df.columns:
            answer_col = col
            break

    if answer_col is None:
        raise ValueError(f"ì •ë‹µ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {list(df.columns)}")

    # ì»¬ëŸ¼ëª… ì •ê·œí™”
    df = df.rename(columns={
        question_col: 'user_input',
        answer_col: 'reference'
    })

    print(f"âœ… Golden Dataset ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ")
    print(f"   ì§ˆë¬¸ ì»¬ëŸ¼: {question_col} â†’ user_input")
    print(f"   ì •ë‹µ ì»¬ëŸ¼: {answer_col} â†’ reference")

    return df


# ============================================================
# LangGraph V1 ëª¨ë¸ ì¶”ë¡ 
# ============================================================
# ============================================================
# LangGraph V1 ëª¨ë¸ ì¶”ë¡ 
# ============================================================
def run_inference(questions: List[str], chatbot_version: str = "v3", verbose: bool = True) -> List[Dict[str, Any]]:
    """
    LangGraph V1 RAG ëª¨ë¸ë¡œ ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€

    Returns:
        List of {answer: str, contexts: List[str]}
    """
    # chatbot_V3.pyì—ì„œ LangGraph ì±—ë´‡ ì´ˆê¸°í™” í•¨ìˆ˜ ìž„í¬íŠ¸
    print(f"\nðŸ¤– LangGraph ëª¨ë¸ ì´ˆê¸°í™” ì¤‘... (ë²„ì „: {chatbot_version})")

    if chatbot_version.lower() == "v1":
        from chatbot_V1 import initialize_langgraph_chatbot
    elif chatbot_version.lower() == "v2":
        from chatbot_V2 import initialize_langgraph_chatbot
    elif chatbot_version.lower() == "v3":
        from chatbot_V3 import initialize_langgraph_chatbot
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì±—ë´‡ ë²„ì „ìž…ë‹ˆë‹¤: {chatbot_version}")

    graph = initialize_langgraph_chatbot()
    print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n")

    results = []

    iterator = tqdm(questions, desc="ì¶”ë¡  ì¤‘") if verbose else questions

    for i, question in enumerate(iterator):
        try:
            if verbose:
                print(f"\nðŸ” ì§ˆë¬¸ [{i+1}]: {question}")

            # LangGraph ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = {
                "messages": [HumanMessage(content=question)],
                "user_query": question,
                "query_analysis": None,
                "retrieved_docs": None,
                "case_law_results": None,
                "generated_answer": None,
                "next_action": None
            }

            # ê·¸ëž˜í”„ ì‹¤í–‰
            result = graph.invoke(initial_state)

            # ë‹µë³€ ì¶”ì¶œ
            answer = result.get("generated_answer", "")

            # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (LangGraph V1ì—ì„œëŠ” retrieved_docsì— Document ê°ì²´ë¡œ ì €ìž¥)
            contexts = []
            retrieved_docs = result.get("retrieved_docs", [])

            if retrieved_docs:
                for doc in retrieved_docs:
                    # Document ê°ì²´ì—ì„œ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    metadata = doc.metadata
                    source = metadata.get("source", "")
                    law_name = metadata.get("law_name", "")
                    article = metadata.get("article_no", "")
                    title = metadata.get(
                        "article_title", "") or metadata.get("title", "")
                    content = doc.page_content.strip()

                    # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… (í‰ê°€ì— ì‚¬ìš©í•  í˜•íƒœë¡œ)
                    context_text = ""
                    if law_name:
                        context_text += f"[{law_name}"
                        if article:
                            context_text += f" ì œ{article}ì¡°"
                        context_text += "]"
                    if title:
                        context_text += f" {title}"
                    if content:
                        context_text += f"\n{content}"

                    if context_text.strip():
                        contexts.append(context_text.strip())

            # íŒë¡€ ê²€ìƒ‰ ê²°ê³¼ë„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ (ìžˆëŠ” ê²½ìš°)
            case_law_results = result.get("case_law_results", [])
            if case_law_results:
                for case in case_law_results:
                    case_text = f"[íŒë¡€] {case.get('title', '')}\n{case.get('content', '')}"
                    if case_text.strip():
                        contexts.append(case_text.strip())

            # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  placeholder ì‚¬ìš© (fallback)
            if not contexts:
                contexts = ["(ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)"]

            results.append({
                "answer": answer,
                "contexts": contexts
            })

            if verbose:
                print(f"   âœ… ì»¨í…ìŠ¤íŠ¸ {len(contexts)}ê°œ ì¶”ì¶œë¨")

        except Exception as e:
            print(f"\nâš ï¸ ì¶”ë¡  ì‹¤íŒ¨: {question[:50]}... - {e}")
            import traceback
            traceback.print_exc()
            results.append({
                "answer": f"[ì˜¤ë¥˜] {str(e)}",
                "contexts": []
            })

    return results


# ============================================================
# Ragas í‰ê°€
# ============================================================
def evaluate_with_ragas(
    questions: List[str],
    answers: List[str],
    contexts: List[List[str]],
    references: List[str],
    llm_model: str = "gpt-4o",
    embedding_model: Any = None
) -> Dict[str, Any]:
    """
    Ragas ë©”íŠ¸ë¦­ìœ¼ë¡œ RAG ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

    Args:
        questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        answers: ìƒì„±ëœ ë‹µë³€ ë¦¬ìŠ¤íŠ¸
        contexts: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        references: ì •ë‹µ(Ground Truth) ë¦¬ìŠ¤íŠ¸
        llm_model: í‰ê°€ì— ì‚¬ìš©í•  LLM ëª¨ë¸

    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("\nðŸ“Š Ragas í‰ê°€ ì‹œìž‘...")

    # Ragas Dataset ìƒì„±
    eval_dataset = Dataset.from_dict({
        "user_input": questions,
        "response": answers,
        "retrieved_contexts": contexts,
        "reference": references
    })

    # í‰ê°€ìš© LLM ë° Embeddings ì„¤ì •
    eval_llm = LangchainLLMWrapper(ChatOpenAI(model=llm_model, temperature=0))
    eval_embeddings = LangchainEmbeddingsWrapper(
        embedding_model) if embedding_model else None

    # ë©”íŠ¸ë¦­ ì •ì˜ (Ragas 0.4.x class-based API)
    metrics = [
        Faithfulness(),
        ResponseRelevancy(),
        LLMContextPrecisionWithoutReference(),
        LLMContextRecall(),
    ]

    # í‰ê°€ ì‹¤í–‰
    try:
        result = evaluate(
            dataset=eval_dataset,
            metrics=metrics,
            llm=eval_llm,
            embeddings=eval_embeddings,
            raise_exceptions=False
        )

        print("âœ… Ragas í‰ê°€ ì™„ë£Œ")
        return result

    except Exception as e:
        print(f"âŒ Ragas í‰ê°€ ì‹¤íŒ¨: {e}")
        raise


# ============================================================
# ê²°ê³¼ ì €ìž¥
# ============================================================
def save_results(
    df: pd.DataFrame,
    ragas_result: Dict,
    output_path: str,
    chatbot_version: str = "V1"
):
    """
    í‰ê°€ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.
    êµ¬ì¡°: { "summary": {metrics...}, "results": [records...] }

    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆìž„ (ì§ˆë¬¸, ì •ë‹µ í¬í•¨)
        ragas_result: Ragas í‰ê°€ ê²°ê³¼
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    import json

    # Ragas ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    result_df = ragas_result.to_pandas()

    # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ì›ë³¸ dfì— ì´ë¯¸ ìžˆëŠ” ì»¬ëŸ¼ì€ result_dfì—ì„œ ì œì™¸)
    cols_to_use = result_df.columns.difference(df.columns)

    # ì›ë³¸ ë°ì´í„°ì™€ ê²°í•©
    final_df = pd.concat(
        [df.reset_index(drop=True),
         result_df[cols_to_use].reset_index(drop=True)],
        axis=1
    )

    # ìš”ì•½ ì •ë³´ ìƒì„± (í‰ê·  ì ìˆ˜)
    # ìš”ì•½ ì •ë³´ ìƒì„± (í‰ê·  ì ìˆ˜)
    summary = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_version": f"LangGraph {chatbot_version.upper()}",
        "metrics": {}
    }

    numeric_cols = result_df.select_dtypes(include=['number']).columns
    for col in numeric_cols:
        summary["metrics"][col] = float(result_df[col].mean())

    # ìµœì¢… ì €ìž¥ ë°ì´í„° êµ¬ì¡°
    output_data = {
        "summary": summary,
        "results": final_df.to_dict(orient='records')
    }

    # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def replace_nan_with_none(obj):
        if isinstance(obj, float) and (obj != obj):  # Check for NaN
            return None
        if isinstance(obj, dict):
            return {k: replace_nan_with_none(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [replace_nan_with_none(v) for v in obj]
        return obj

    output_data = replace_nan_with_none(output_data)

    # ì €ìž¥
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def replace_nan_with_none(obj):
        if isinstance(obj, float) and (obj != obj):  # Check for NaN
            return None
        if isinstance(obj, dict):
            return {k: replace_nan_with_none(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [replace_nan_with_none(v) for v in obj]
        return obj

    output_data = replace_nan_with_none(output_data)

    # ì €ìž¥
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nðŸ’¾ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ: {output_path}")
    print(f"   (ìƒë‹¨ summary í¬í•¨)")


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description='ë…¸ë™ë²• RAG ì±—ë´‡ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (LangGraph V1)')
    parser.add_argument(
        '--golden-set',
        type=str,
        default='a_team/data/evaluation/labor_law_golden_set.json',
        help='Golden Dataset JSON ê²½ë¡œ'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='ê²°ê³¼ ì €ìž¥ ê²½ë¡œ (ê¸°ë³¸ê°’: golden_set í´ë”ì— ì €ìž¥)'
    )
    parser.add_argument(
        '--sample',
        type=int,
        default=0,
        help='í‰ê°€í•  ìƒ˜í”Œ ìˆ˜ (0ì´ë©´ ì „ì²´ í‰ê°€)'
    )
    parser.add_argument(
        '--eval-model',
        type=str,
        default='gpt-4o',
        help='Ragas í‰ê°€ì— ì‚¬ìš©í•  LLM ëª¨ë¸'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ë°ì´í„° ë¡œë“œë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì¢…ë£Œ'
    )
    parser.add_argument(
        '--chatbot-version',
        type=str,
        default='v3',
        choices=['v1', 'v2', 'v3'],
        help='í‰ê°€í•  ì±—ë´‡ ë²„ì „ (v1, v2, v3)'
    )
    args = parser.parse_args()

    # API Key í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    print("=" * 60)
    print("ðŸ›ï¸  ë…¸ë™ë²• RAG ì±—ë´‡ í‰ê°€ ì‹œìž‘ (LangGraph V1)")
    print("=" * 60)

    # 1. Golden Dataset ë¡œë“œ
    df = load_golden_dataset(args.golden_set)

    # ìƒ˜í”Œë§
    if args.sample > 0 and args.sample < len(df):
        df = df.sample(n=args.sample, random_state=42).reset_index(drop=True)
        print(f"âœ‚ï¸  {args.sample}ê°œ ìƒ˜í”Œë¡œ ì œí•œ")

    # Dry run ëª¨ë“œ
    if args.dry_run:
        print("\nðŸ§ª Dry Run ëª¨ë“œ: ë°ì´í„° ë¡œë“œë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        print(f"\nìƒ˜í”Œ ë°ì´í„°:")
        print(df.head(3).to_string())
        return

    # 2. LangGraph V1 ëª¨ë¸ ì¶”ë¡ 
    questions = df['user_input'].tolist()
    references = df['reference'].tolist()

    print(f"\nðŸ“ {len(questions)}ê°œ ì§ˆë¬¸ì— ëŒ€í•´ ì¶”ë¡  ì‹œìž‘ (Chatbot {args.chatbot_version})...")
    inference_results = run_inference(
        questions, chatbot_version=args.chatbot_version)

    # ê²°ê³¼ ì¶”ì¶œ
    answers = [r['answer'] for r in inference_results]
    contexts = [r['contexts'] for r in inference_results]

    # DataFrameì— ì¶”ë¡  ê²°ê³¼ ì¶”ê°€
    df['generated_answer'] = answers
    df['retrieved_contexts'] = [str(c) for c in contexts]  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìžì—´ë¡œ
    # 3. ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ (Qwen) - Ragas í‰ê°€ìš©
    print(f"\nðŸš€ í‰ê°€ìš© ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ (Qwen/Qwen3-Embedding-0.6B)...")
    embeddings = HuggingFaceEmbeddings(
        model_name="Qwen/Qwen3-Embedding-0.6B",
        model_kwargs={'trust_remote_code': True},
        encode_kwargs={'normalize_embeddings': True}
    )

    # 4. Ragas í‰ê°€
    ragas_result = evaluate_with_ragas(
        questions=questions,
        answers=answers,
        contexts=contexts,
        references=references,
        llm_model=args.eval_model,
        embedding_model=embeddings
    )
    # 4. ê²°ê³¼ ì €ìž¥ (ì¶œë ¥ ì „ì— ë¨¼ì € ì €ìž¥!)
    if args.output:
        output_path = args.output
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path(args.golden_set).parent
        output_path = output_dir / f"evaluation_results_V1_{timestamp}.json"

    try:
        save_results(df, ragas_result, str(output_path),
                     chatbot_version=args.chatbot_version)
    except Exception as e:
        print(f"âš ï¸ ê²°ê³¼ ì €ìž¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 5. ê²°ê³¼ ì¶œë ¥ (DataFrame ì‚¬ìš©)
    print("\n" + "=" * 60)
    print("ðŸ“Š í‰ê°€ ê²°ê³¼ ìš”ì•½ (LangGraph V1)")
    print("=" * 60)

    try:
        # Ragas ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‰ê·  ê³„ì‚°
        result_df = ragas_result.to_pandas()
        numeric_cols = result_df.select_dtypes(include=['number']).columns

        for col in numeric_cols:
            avg_score = result_df[col].mean()
            print(f"  â€¢ {col}: {avg_score:.4f}")

    except Exception as e:
        print(f"âš ï¸ ê²°ê³¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°ì´í„°ëŠ” ì €ìž¥ë¨): {e}")

    print("\n" + "=" * 60)
    print("âœ… í‰ê°€ ì™„ë£Œ! (LangGraph V1)")
    print("=" * 60)


if __name__ == "__main__":
    main()
