"""
ë…¸ë™ë²• RAG ì±—ë´‡ í‰ê°€ìš© Golden Set ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Ragas 0.4.x)

Ragas TestsetGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬ PDF/í…ìŠ¤íŠ¸ ë¬¸ì„œë¡œë¶€í„°
ë‹¤ì–‘í•œ ìœ í˜•ì˜ í‰ê°€ìš© ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

Tech Stack:
    - Python 3.10+
    - ragas 0.4.x
    - langchain / langchain-openai / langchain-community
    - pandas

Usage:
    # ê¸°ë³¸ ì‹¤í–‰ (OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)
    python generate_golden_dataset.py

    # ìƒì„±í•  í…ŒìŠ¤íŠ¸ì…‹ í¬ê¸° ì§€ì •
    python generate_golden_dataset.py --test-size 50

    # ë°ì´í„° í´ë” ê²½ë¡œ ì§€ì •
    python generate_golden_dataset.py --data-dir ./custom_data
"""

import os
import warnings
from pathlib import Path
from ragas.testset import TestsetGenerator
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader

import pandas as pd
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§ (ì„ íƒì‚¬í•­)
warnings.filterwarnings("ignore", category=DeprecationWarning)


def load_documents_from_qdrant(
    collection_name: str = None,
    limit: int = 0
) -> list:
    """
    Qdrant DBì—ì„œ ì²­í‚¹ëœ ë¬¸ì„œë¥¼ ì§ì ‘ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ì‹¤ì œ ë²¡í„° DBì— ì €ì¥ëœ ì²­í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Golden Setì„ ë§Œë“¤ë©´
    Context Precision/Recall í‰ê°€ê°€ ì •í™•í•´ì§‘ë‹ˆë‹¤.

    Args:
        collection_name: Qdrant ì»¬ë ‰ì…˜ ì´ë¦„ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ QDRANT_COLLECTION_NAME)
        limit: ê°€ì ¸ì˜¬ ìµœëŒ€ ë¬¸ì„œ ìˆ˜ (0ì´ë©´ ì „ì²´)

    Returns:
        List of LangChain Document objects
    """
    from langchain_core.documents import Document
    from qdrant_client import QdrantClient

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ Qdrant ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    qdrant_url = os.getenv("QDRANT_URL")
    qdrant_api_key = os.getenv("QDRANT_API_KEY")
    collection = collection_name or os.getenv(
        "QDRANT_COLLECTION_NAME", "A-TEAM")

    print(f"ğŸ“‚ Qdrant DBì—ì„œ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    print(f"   Collection: {collection}")

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    if qdrant_url and qdrant_api_key:
        print(f"   URL: {qdrant_url[:30]}...")
        client = QdrantClient(
            url=qdrant_url,
            api_key=qdrant_api_key,
            timeout=60
        )
    else:
        # ë¡œì»¬ Docker Qdrant
        print("   Local Docker: localhost:6333")
        client = QdrantClient(host="localhost", port=6333)

    # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
    try:
        collection_info = client.get_collection(collection_name=collection)
        total_points = collection_info.points_count
        print(f"   ì´ í¬ì¸íŠ¸ ìˆ˜: {total_points}")
    except Exception as e:
        raise ConnectionError(f"Qdrant ì»¬ë ‰ì…˜ '{collection}'ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    # ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ìŠ¤í¬ë¡¤ API ì‚¬ìš©)
    documents = []
    offset = None
    batch_size = 100

    while True:
        # Qdrantì—ì„œ ë°°ì¹˜ë¡œ í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        results = client.scroll(
            collection_name=collection,
            limit=batch_size,
            offset=offset,
            with_payload=True,
            with_vectors=False  # ë²¡í„°ëŠ” í•„ìš” ì—†ìŒ
        )

        points, next_offset = results

        if not points:
            break

        for point in points:
            payload = point.payload or {}
            text = payload.get("text", "")

            if text and len(text) > 30:
                doc = Document(
                    page_content=text,
                    metadata={
                        "id": str(point.id),
                        "source": payload.get("source", ""),
                        "law_name": payload.get("law_name", ""),
                        "law_id": payload.get("law_id", ""),
                        "article_no": payload.get("article_no", ""),
                        "article_title": payload.get("article_title", ""),
                        "paragraph_no": payload.get("paragraph_no", ""),
                        "chunk_type": payload.get("chunk_type", ""),
                        "category": payload.get("category", ""),
                        "chunk_index": payload.get("chunk_index", 0),
                    }
                )
                documents.append(doc)

        # ë‹¤ìŒ ë°°ì¹˜
        offset = next_offset

        # limitì´ ì§€ì •ë˜ì–´ ìˆê³  ë„ë‹¬í–ˆìœ¼ë©´ ì¤‘ë‹¨
        if limit > 0 and len(documents) >= limit:
            documents = documents[:limit]
            break

        if next_offset is None:
            break

    # ì†ŒìŠ¤ë³„ í†µê³„ ì¶œë ¥
    source_counts = {}
    for doc in documents:
        src = doc.metadata.get("source", "unknown")
        source_counts[src] = source_counts.get(src, 0) + 1

    print(f"\n   ğŸ“Š ì†ŒìŠ¤ë³„ ë¬¸ì„œ ìˆ˜:")
    for src, count in sorted(source_counts.items()):
        print(f"      â€¢ {src}: {count}ê°œ")

    print(f"\nğŸ“„ ì´ {len(documents)}ê°œ ì²­í‚¹ëœ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n")
    return documents

# ---------------------------------------------------------
# [ìˆ˜ì •] ì˜¨ë„ë¥¼ ê°•ì œë¡œ 1ë¡œ ê³ ì •í•˜ëŠ” ì»¤ìŠ¤í…€ LLM í´ë˜ìŠ¤
# (ì¼ë¶€ ëª¨ë¸ì´ temperature!=1ì„ ì§€ì›í•˜ì§€ ì•Šì„ ë•Œ ì‚¬ìš©)
# ---------------------------------------------------------


class ForceTemperature1ChatOpenAI(ChatOpenAI):
    def _generate(self, messages, stop=None, run_manager=None, **kwargs):
        if 'temperature' in kwargs:
            kwargs['temperature'] = 1
        return super()._generate(messages, stop=stop, run_manager=run_manager, **kwargs)

    async def _agenerate(self, messages, stop=None, run_manager=None, **kwargs):
        if 'temperature' in kwargs:
            kwargs['temperature'] = 1
        return await super()._agenerate(messages, stop=stop, run_manager=run_manager, **kwargs)


def setup_generator(model_name: str = "gpt-5.2") -> TestsetGenerator:
    """
    Ragas 0.4.x TestsetGeneratorë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

    Args:
        model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª… (gpt-4o, gpt-4-turbo ë“±)

    Returns:
        ì„¤ì •ëœ TestsetGenerator ì¸ìŠ¤í„´ìŠ¤
    """
    print(f"ğŸ¤– LLM ì„¤ì • ì¤‘: {model_name}")

    # ---------------------------------------------------------
    # Generator LLM ì„¤ì • (ì»¤ìŠ¤í…€ ë˜í¼ ì‚¬ìš©)
    # ì…ë ¥ ë¬¸ì„œê°€ í•œêµ­ì–´ì´ë¯€ë¡œ ì¶œë ¥ë„ í•œêµ­ì–´ë¡œ ìƒì„±ë¨
    # ---------------------------------------------------------
    generator_llm = ForceTemperature1ChatOpenAI(
        model=model_name,
        temperature=1,
    )

    # ---------------------------------------------------------
    # Embeddings ì„¤ì •
    # ---------------------------------------------------------
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-large"
    )

    # ---------------------------------------------------------
    # Ragas 0.4.x: TestsetGenerator.from_langchain() ì‚¬ìš©
    # ---------------------------------------------------------
    generator = TestsetGenerator.from_langchain(
        llm=generator_llm,
        embedding_model=embeddings
    )

    print("âœ… TestsetGenerator ì„¤ì • ì™„ë£Œ\n")
    return generator


def generate_testset(
    generator: TestsetGenerator,
    documents: list,
    test_size: int = 30
) -> pd.DataFrame:
    """
    ë¬¸ì„œë¡œë¶€í„° í…ŒìŠ¤íŠ¸ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        generator: ì„¤ì •ëœ TestsetGenerator
        documents: ë¡œë“œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        test_size: ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì…‹ DataFrame
    """
    from ragas.run_config import RunConfig

    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì¤‘ (ëª©í‘œ: {test_size}ê°œ)")
    print("   ë…¸ë™ë²• íŠ¹ì„±ìƒ ì¡°ê±´ë¶€/ì¶”ë¡  ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ë§ì´ ìƒì„±ë©ë‹ˆë‹¤.")
    print()

    # ---------------------------------------------------------
    # RunConfig: ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë° ì˜ˆì™¸ ë¬´ì‹œ ì„¤ì •
    # ---------------------------------------------------------
    run_config = RunConfig(
        max_retries=3,           # ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„
        max_wait=60,             # ì¬ì‹œë„ ê°„ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
        max_workers=4,           # ë™ì‹œ ì²˜ë¦¬ ìˆ˜ ì œí•œ
        timeout=120,             # ê°œë³„ ì‘ì—… íƒ€ì„ì•„ì›ƒ
        exception_types=(Exception,),  # ëª¨ë“  ì˜ˆì™¸ ì¬ì‹œë„
    )

    # ---------------------------------------------------------
    # Ragas 0.4.x: generate_with_langchain_docs ë©”ì„œë“œ ì‚¬ìš©
    # ---------------------------------------------------------
    try:
        testset = generator.generate_with_langchain_docs(
            documents=documents,
            testset_size=test_size,
            raise_exceptions=False,
            run_config=run_config,
        )
    except Exception as e:
        print(f"\nâš ï¸ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        print("   ì¼ë¶€ ë¬¸ì„œì—ì„œ íŒŒì‹± ì‹¤íŒ¨. ìƒ˜í”Œ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        raise

    # DataFrameìœ¼ë¡œ ë³€í™˜
    df = testset.to_pandas()

    print(f"\nâœ… {len(df)}ê°œ ì§ˆë¬¸-ë‹µë³€ ìŒ ìƒì„± ì™„ë£Œ")
    return df


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    # ---------------------------------------------------------
    # CLI ì¸ì íŒŒì‹±
    # ---------------------------------------------------------
    parser = argparse.ArgumentParser(
        description='ë…¸ë™ë²• RAG í‰ê°€ìš© Golden Set ìƒì„± (Ragas 0.4.x TestsetGenerator)'
    )
    parser.add_argument(
        '--collection',
        type=str,
        default=None,
        help='Qdrant ì»¬ë ‰ì…˜ ì´ë¦„ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ QDRANT_COLLECTION_NAME)'
    )
    parser.add_argument(
        '--test-size',
        type=int,
        default=30,
        help='ìƒì„±í•  í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ê°œìˆ˜ (ê¸°ë³¸ê°’: 30)'
    )
    parser.add_argument(
        '--sample-size',
        type=int,
        default=200,
        help='ì‚¬ìš©í•  ë¬¸ì„œ ìƒ˜í”Œë§ ê°œìˆ˜ (0ì´ë©´ ì „ì²´ ì‚¬ìš©, ê¸°ë³¸ê°’: 200)'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='gpt-5-mini',
        help='ì‚¬ìš©í•  LLM ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-5-mini)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='labor_law_golden_set.json',
        help='ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: labor_law_golden_set.json)'
    )
    args = parser.parse_args()

    # ---------------------------------------------------------
    # API í‚¤ í™•ì¸
    # ---------------------------------------------------------
    if not os.environ.get("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("   export OPENAI_API_KEY='your-api-key'")
        return

    print("=" * 60)
    print("ğŸ›ï¸  ë…¸ë™ë²• RAG í‰ê°€ìš© Golden Set ìƒì„±ê¸° (Ragas 0.4.x)")
    print("=" * 60)
    print()

    # ---------------------------------------------------------
    # Step 1: ë¬¸ì„œ ë¡œë“œ
    # ---------------------------------------------------------
    documents = load_documents_from_qdrant(
        collection_name=args.collection,
        limit=args.sample_size
    )

    if not documents:
        print("âŒ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. Qdrant ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # ---------------------------------------------------------
    # Step 2: Generator ì„¤ì •
    # ---------------------------------------------------------
    generator = setup_generator(args.model)

    # ---------------------------------------------------------
    # Step 3: í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±
    # ---------------------------------------------------------
    df = generate_testset(
        generator=generator,
        documents=documents,
        test_size=args.test_size
    )

    # ---------------------------------------------------------
    # Step 4: ê²°ê³¼ ì €ì¥
    # ---------------------------------------------------------
    script_dir = Path(__file__).parent
    output_dir = script_dir.parent / "data" / "evaluation"
    output_dir.mkdir(parents=True, exist_ok=True)

    output_path = output_dir / args.output
    df.to_json(output_path, orient='records', force_ascii=False, indent=2)

    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")

    # ---------------------------------------------------------
    # Step 5: ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    # ---------------------------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“Š ìƒì„±ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    print("=" * 60)
    print(f"\nì»¬ëŸ¼: {list(df.columns)}")

    print("\nìƒ˜í”Œ ì§ˆë¬¸ 3ê°œ:")
    for i, row in df.head(3).iterrows():
        q = row.get('user_input', row.get('question', 'N/A'))
        a = row.get('reference', row.get('ground_truth', 'N/A'))
        print(f"\n[{i+1}] Q: {str(q)[:80]}...")
        print(f"    A: {str(a)[:80]}...")


if __name__ == '__main__':
    main()
