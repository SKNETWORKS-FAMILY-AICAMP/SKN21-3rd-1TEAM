"""
ë²•ë ¹ ë°ì´í„° Qdrant ë²¡í„° DB ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (Unified / BGE-M3)
- common.vector_db.LegalVectorDB ì‚¬ìš©
<<<<<<< HEAD
- ë¡œì»¬ ë˜ëŠ” í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì„ íƒ ê°€ëŠ¥
"""
import os
import sys
import json
import argparse
from pathlib import Path
from dotenv import load_dotenv

# Common Module Import (Fix: 3 levels up to reach project root)
sys.path.append(os.path.abspath(os.path.join(
    os.path.dirname(__file__), '..', '..', '..')))

from a_team.scripts.common.vector_db import LegalVectorDB  # noqa: E402 # isort: skip

=======
"""
from a_team.scripts.common.vector_db import LegalVectorDB
import os
import sys
import json
from pathlib import Path
from dotenv import load_dotenv

# Common Module Import (Fix: 3 levels up to reach project root)
sys.path.append(os.path.abspath(os.path.join(
    os.path.dirname(__file__), '..', '..', '..')))
>>>>>>> 209151e353aba59a2423f8158163afcb4a0cdf48

# ============================================================
# ì„¤ì •
# ============================================================

SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR / '..' / '..' / 'data'
PROCESSED_FILE = DATA_DIR / 'processed' / 'fd_ë²•ë ¹_chunked.json'
LOCAL_QDRANT_PATH = DATA_DIR / 'qdrant_local'

EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-0.6B"
SPARSE_MODEL = "BAAI/bge-m3"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Project Root .env)
# scripts/data_preprocessing/../../.. -> Project Root
PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent
ENV_PATH = PROJECT_ROOT / '.env'
if not ENV_PATH.exists():
    # Try finding it relative to current working dir if script assumption fails
    ENV_PATH = Path(os.getcwd()) / '.env'

print(f"ğŸŒ Loading .env from: {ENV_PATH}")
load_dotenv(ENV_PATH)

QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "A-TEAM")


def load_json(filepath):
    """JSON íŒŒì¼ ë¡œë“œ"""
    print(f"ğŸ“‚ Loading: {filepath}")
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)
<<<<<<< HEAD


def parse_args():
    """ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="ë²•ë ¹ ë°ì´í„°ë¥¼ Qdrantì— ì—…ë¡œë“œ (Hybrid Search)"
    )
    parser.add_argument(
        '--storage-mode',
        type=str,
        choices=['local', 'cloud', 'server'],
        default='cloud',
        help='Qdrant ì €ì¥ì†Œ ëª¨ë“œ ì„ íƒ (local: ë¡œì»¬ ë””ìŠ¤í¬, cloud: Qdrant Cloud, server: Docker ì„œë²„)'
    )
    parser.add_argument(
        '--local-path',
        type=str,
        default=str(LOCAL_QDRANT_PATH),
        help='ë¡œì»¬ ì €ì¥ì†Œ ê²½ë¡œ (storage-mode=localì¼ ë•Œ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--collection-name',
        type=str,
        default=COLLECTION_NAME,
        help='Qdrant ì»¬ë ‰ì…˜ ì´ë¦„'
    )
    parser.add_argument(
        '--recreate',
        action='store_true',
        help='ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=12,
        help='ì—…ë¡œë“œ ë°°ì¹˜ í¬ê¸°'
    )
    parser.add_argument(
        '--force-cpu',
        action='store_true',
        help='MPS ëŒ€ì‹  CPU ì‚¬ìš© (ëŠë¦¬ì§€ë§Œ ë©”ëª¨ë¦¬ ì•ˆì •ì )'
    )
    parser.add_argument(
        '--start-index',
        type=int,
        default=0,
        help='ì‹œì‘ ì²­í¬ ì¸ë±ìŠ¤ (ë³‘ë ¬ ì²˜ë¦¬ìš©)'
    )
    parser.add_argument(
        '--end-index',
        type=int,
        default=None,
        help='ì¢…ë£Œ ì²­í¬ ì¸ë±ìŠ¤ (ë³‘ë ¬ ì²˜ë¦¬ìš©, None=ëê¹Œì§€)'
    )
    return parser.parse_args()
=======
>>>>>>> 209151e353aba59a2423f8158163afcb4a0cdf48


def main():
    args = parse_args()

    print("=" * 60)
    print("âš–ï¸  ë²•ë ¹ ë°ì´í„° Qdrant ì—…ë¡œë“œ (Hybrid: Qwen + BGE-M3)")
<<<<<<< HEAD
    print(f"ğŸ“¦ ì €ì¥ì†Œ ëª¨ë“œ: {args.storage_mode.upper()}")
=======
>>>>>>> 209151e353aba59a2423f8158163afcb4a0cdf48
    print("=" * 60)

    if not PROCESSED_FILE.exists():
        print(f"âŒ ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {PROCESSED_FILE}")
        print("ğŸ’¡ ë¨¼ì € 'uv run a_team/scripts/data_preprocessing/preprocesser_ë²•ë ¹.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

<<<<<<< HEAD
    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë³€ê²½ (ë©”ëª¨ë¦¬ íš¨ìœ¨: ~1GB â†’ ~50MB)
    from a_team.scripts.common.json_utils import stream_json_array, count_json_array_items

    print("ğŸ“Š ì²­í¬ ìˆ˜ í™•ì¸ ì¤‘...")
    total_chunks = count_json_array_items(PROCESSED_FILE)
    print(f"ğŸ“Š ì´ ì²­í¬: {total_chunks:,}ê°œ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)")

    # DB ì´ˆê¸°í™” (ì €ì¥ì†Œ ëª¨ë“œì— ë”°ë¼)
    if args.storage_mode == 'local':
        print(f"ğŸ’¾ ë¡œì»¬ ì €ì¥ì†Œ ì‚¬ìš©: {args.local_path}")
        db = LegalVectorDB(
            local_path=args.local_path,
            dense_model_name=EMBEDDING_MODEL,
            sparse_model_name=SPARSE_MODEL,
            force_cpu=args.force_cpu
        )
    elif args.storage_mode == 'cloud':
        print(f"ğŸŒ í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì‚¬ìš©")
        if not QDRANT_URL or not QDRANT_API_KEY:
            print("âŒ .env íŒŒì¼ì— QDRANT_URLê³¼ QDRANT_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return
        db = LegalVectorDB(
            url=QDRANT_URL,
            api_key=QDRANT_API_KEY,
            dense_model_name=EMBEDDING_MODEL,
            sparse_model_name=SPARSE_MODEL,
            force_cpu=args.force_cpu
        )
    else:  # server
        print(f"ğŸ  ì„œë²„ ëª¨ë“œ ì‚¬ìš© (localhost:6333)")
        db = LegalVectorDB(
            host='localhost',
            port=6333,
            dense_model_name=EMBEDDING_MODEL,
            sparse_model_name=SPARSE_MODEL,
            force_cpu=args.force_cpu
        )

    # ì»¬ë ‰ì…˜ ìƒì„±
    db.create_collection(args.collection_name, recreate=args.recreate)

    # ì´ì–´ì„œ ì—…ë¡œë“œ (í˜„ì¬ ì €ì¥ëœ ì²­í¬ ìˆ˜ í™•ì¸)
    if not args.recreate:
        info = db.get_collection_info(args.collection_name)
        start_idx = info['points_count']
        if start_idx > 0:
            print(
                f"\nğŸ”„ ì´ì–´ì„œ ì—…ë¡œë“œ: {start_idx:,}ê°œ ì´ë¯¸ ì €ì¥ë¨, {total_chunks - start_idx:,}ê°œ ë‚¨ìŒ")
        else:
            print(f"\nğŸ†• ìƒˆë¡œìš´ ì—…ë¡œë“œ ì‹œì‘")
        start_id = start_idx
    else:
        start_id = 0
        start_idx = 0

    if start_idx >= total_chunks:
        print("âœ… ëª¨ë“  ì²­í¬ê°€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return

    # ë°°ì¹˜ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨: 5000ê°œì”© ë¡œë“œ)
    print(f"\nğŸš€ ë°°ì¹˜ ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ (ì—…ë¡œë“œ ë°°ì¹˜: {args.batch_size}, ë©”ëª¨ë¦¬ ë°°ì¹˜: 5000)...")

    processed_count = 0
    for batch_chunks in stream_json_array(PROCESSED_FILE, batch_size=5000):
        # ì´ë¯¸ ì²˜ë¦¬ëœ ì²­í¬ ê±´ë„ˆë›°ê¸°
        if processed_count + len(batch_chunks) <= start_idx:
            processed_count += len(batch_chunks)
            continue

        # ë¶€ë¶„ì ìœ¼ë¡œ ì²˜ë¦¬ëœ ë°°ì¹˜ ì²˜ë¦¬
        if processed_count < start_idx:
            skip_count = start_idx - processed_count
            batch_chunks = batch_chunks[skip_count:]
            processed_count = start_idx

        # ì—…ë¡œë“œ
        current_start_id = start_id + (processed_count - start_idx)
        db.upsert_chunks(args.collection_name, batch_chunks,
                         batch_size=args.batch_size,
                         start_id=current_start_id)

        processed_count += len(batch_chunks)

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del batch_chunks
        import gc
        gc.collect()

    print("\n" + "=" * 60)
    print(f"âœ… ì™„ë£Œ! ì»¬ë ‰ì…˜ '{args.collection_name}'ì— ì´ {total_chunks:,}ê°œ ì²­í¬ ì €ì¥ë¨")
    if args.storage_mode == 'local':
        print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {args.local_path}")
    print("=" * 60)
=======
    chunks = load_json(PROCESSED_FILE)
    print(f"ğŸ“Š ë¡œë“œëœ ì²­í¬: {len(chunks)}ê°œ")

    # DB ì´ˆê¸°í™”
    db = LegalVectorDB(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
        dense_model_name=EMBEDDING_MODEL,
        sparse_model_name=SPARSE_MODEL
    )

    # ì»¬ë ‰ì…˜ ìƒì„± (Main Script -> recreate=True)
    db.create_collection(COLLECTION_NAME, recreate=True)

    # ì—…ì„œíŠ¸
    db.upsert_chunks(COLLECTION_NAME, chunks, batch_size=12)
>>>>>>> 209151e353aba59a2423f8158163afcb4a0cdf48


if __name__ == "__main__":
    main()
