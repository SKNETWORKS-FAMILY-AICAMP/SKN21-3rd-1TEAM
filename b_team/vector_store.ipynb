{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31baff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-text-splitters qdrant-client langchain-qdrant sentence-transformers torch torchvision torchaudio\n",
    "# !pip install ragas rapidfuzz ipywidgets langchain-huggingface accelerate\n",
    "\n",
    "#!pip install ragas datasets pandas openai\n",
    "#!pip install langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd2a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "import torch,uuid\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings ,HuggingFacePipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "## ragas\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics.collections import Faithfulness, AnswerRelevancy\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52746bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 글자 수: 4,987,798자\n"
     ]
    }
   ],
   "source": [
    "### 파일 data load\n",
    "\n",
    "# 파일 경로 지정\n",
    "file_path = '사회복지_법령_전체.txt'\n",
    "\n",
    "# 파일 내용이 담긴 변수\n",
    "law_data=''\n",
    "\n",
    "\n",
    "# 파일 내용 load\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        law_data = f.read()\n",
    "    print(f\"전체 글자 수: {len(law_data):,}자\")\n",
    "except FileNotFoundError:\n",
    "    print(\"파일을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a36d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1764, which is longer than the specified 1\n",
      "Created a chunk of size 329, which is longer than the specified 1\n",
      "Created a chunk of size 1064, which is longer than the specified 1\n",
      "Created a chunk of size 1089, which is longer than the specified 1\n",
      "Created a chunk of size 1017, which is longer than the specified 1\n",
      "Created a chunk of size 2752, which is longer than the specified 1\n",
      "Created a chunk of size 2117, which is longer than the specified 1\n",
      "Created a chunk of size 449, which is longer than the specified 1\n",
      "Created a chunk of size 459, which is longer than the specified 1\n",
      "Created a chunk of size 2846, which is longer than the specified 1\n",
      "Created a chunk of size 1244, which is longer than the specified 1\n",
      "Created a chunk of size 1147, which is longer than the specified 1\n",
      "Created a chunk of size 3147, which is longer than the specified 1\n",
      "Created a chunk of size 4551, which is longer than the specified 1\n",
      "Created a chunk of size 8678, which is longer than the specified 1\n",
      "Created a chunk of size 2794, which is longer than the specified 1\n",
      "Created a chunk of size 6594, which is longer than the specified 1\n",
      "Created a chunk of size 3128, which is longer than the specified 1\n",
      "Created a chunk of size 3636, which is longer than the specified 1\n",
      "Created a chunk of size 6606, which is longer than the specified 1\n",
      "Created a chunk of size 3646, which is longer than the specified 1\n",
      "Created a chunk of size 2973, which is longer than the specified 1\n",
      "Created a chunk of size 7627, which is longer than the specified 1\n",
      "Created a chunk of size 18674, which is longer than the specified 1\n",
      "Created a chunk of size 6165, which is longer than the specified 1\n",
      "Created a chunk of size 7709, which is longer than the specified 1\n",
      "Created a chunk of size 680, which is longer than the specified 1\n",
      "Created a chunk of size 4950, which is longer than the specified 1\n",
      "Created a chunk of size 3193, which is longer than the specified 1\n",
      "Created a chunk of size 1926, which is longer than the specified 1\n",
      "Created a chunk of size 1395, which is longer than the specified 1\n",
      "Created a chunk of size 9839, which is longer than the specified 1\n",
      "Created a chunk of size 3701, which is longer than the specified 1\n",
      "Created a chunk of size 3071, which is longer than the specified 1\n",
      "Created a chunk of size 21132, which is longer than the specified 1\n",
      "Created a chunk of size 11302, which is longer than the specified 1\n",
      "Created a chunk of size 4930, which is longer than the specified 1\n",
      "Created a chunk of size 15666, which is longer than the specified 1\n",
      "Created a chunk of size 33913, which is longer than the specified 1\n",
      "Created a chunk of size 3453, which is longer than the specified 1\n",
      "Created a chunk of size 11619, which is longer than the specified 1\n",
      "Created a chunk of size 6270, which is longer than the specified 1\n",
      "Created a chunk of size 16355, which is longer than the specified 1\n",
      "Created a chunk of size 2471, which is longer than the specified 1\n",
      "Created a chunk of size 21080, which is longer than the specified 1\n",
      "Created a chunk of size 13465, which is longer than the specified 1\n",
      "Created a chunk of size 4833, which is longer than the specified 1\n",
      "Created a chunk of size 18599, which is longer than the specified 1\n",
      "Created a chunk of size 58000, which is longer than the specified 1\n",
      "Created a chunk of size 9346, which is longer than the specified 1\n",
      "Created a chunk of size 23130, which is longer than the specified 1\n",
      "Created a chunk of size 2104, which is longer than the specified 1\n",
      "Created a chunk of size 20530, which is longer than the specified 1\n",
      "Created a chunk of size 90129, which is longer than the specified 1\n",
      "Created a chunk of size 13044, which is longer than the specified 1\n",
      "Created a chunk of size 9085, which is longer than the specified 1\n",
      "Created a chunk of size 1639, which is longer than the specified 1\n",
      "Created a chunk of size 8546, which is longer than the specified 1\n",
      "Created a chunk of size 4671, which is longer than the specified 1\n",
      "Created a chunk of size 9596, which is longer than the specified 1\n",
      "Created a chunk of size 7244, which is longer than the specified 1\n",
      "Created a chunk of size 12833, which is longer than the specified 1\n",
      "Created a chunk of size 19554, which is longer than the specified 1\n",
      "Created a chunk of size 12110, which is longer than the specified 1\n",
      "Created a chunk of size 7116, which is longer than the specified 1\n",
      "Created a chunk of size 18095, which is longer than the specified 1\n",
      "Created a chunk of size 7336, which is longer than the specified 1\n",
      "Created a chunk of size 8009, which is longer than the specified 1\n",
      "Created a chunk of size 11537, which is longer than the specified 1\n",
      "Created a chunk of size 5270, which is longer than the specified 1\n",
      "Created a chunk of size 2028, which is longer than the specified 1\n",
      "Created a chunk of size 32406, which is longer than the specified 1\n",
      "Created a chunk of size 10122, which is longer than the specified 1\n",
      "Created a chunk of size 8075, which is longer than the specified 1\n",
      "Created a chunk of size 23211, which is longer than the specified 1\n",
      "Created a chunk of size 58154, which is longer than the specified 1\n",
      "Created a chunk of size 9279, which is longer than the specified 1\n",
      "Created a chunk of size 10516, which is longer than the specified 1\n",
      "Created a chunk of size 21054, which is longer than the specified 1\n",
      "Created a chunk of size 31232, which is longer than the specified 1\n",
      "Created a chunk of size 11723, which is longer than the specified 1\n",
      "Created a chunk of size 19960, which is longer than the specified 1\n",
      "Created a chunk of size 13839, which is longer than the specified 1\n",
      "Created a chunk of size 28535, which is longer than the specified 1\n",
      "Created a chunk of size 14425, which is longer than the specified 1\n",
      "Created a chunk of size 12355, which is longer than the specified 1\n",
      "Created a chunk of size 13031, which is longer than the specified 1\n",
      "Created a chunk of size 23185, which is longer than the specified 1\n",
      "Created a chunk of size 12849, which is longer than the specified 1\n",
      "Created a chunk of size 7076, which is longer than the specified 1\n",
      "Created a chunk of size 28447, which is longer than the specified 1\n",
      "Created a chunk of size 5461, which is longer than the specified 1\n",
      "Created a chunk of size 14893, which is longer than the specified 1\n",
      "Created a chunk of size 33060, which is longer than the specified 1\n",
      "Created a chunk of size 15135, which is longer than the specified 1\n",
      "Created a chunk of size 7337, which is longer than the specified 1\n",
      "Created a chunk of size 51484, which is longer than the specified 1\n",
      "Created a chunk of size 16964, which is longer than the specified 1\n",
      "Created a chunk of size 68510, which is longer than the specified 1\n",
      "Created a chunk of size 13195, which is longer than the specified 1\n",
      "Created a chunk of size 13617, which is longer than the specified 1\n",
      "Created a chunk of size 30960, which is longer than the specified 1\n",
      "Created a chunk of size 41966, which is longer than the specified 1\n",
      "Created a chunk of size 84167, which is longer than the specified 1\n",
      "Created a chunk of size 93477, which is longer than the specified 1\n",
      "Created a chunk of size 34369, which is longer than the specified 1\n",
      "Created a chunk of size 29923, which is longer than the specified 1\n",
      "Created a chunk of size 9728, which is longer than the specified 1\n",
      "Created a chunk of size 7720, which is longer than the specified 1\n",
      "Created a chunk of size 8845, which is longer than the specified 1\n",
      "Created a chunk of size 15205, which is longer than the specified 1\n",
      "Created a chunk of size 12422, which is longer than the specified 1\n",
      "Created a chunk of size 92642, which is longer than the specified 1\n",
      "Created a chunk of size 38109, which is longer than the specified 1\n",
      "Created a chunk of size 14234, which is longer than the specified 1\n",
      "Created a chunk of size 5258, which is longer than the specified 1\n",
      "Created a chunk of size 9748, which is longer than the specified 1\n",
      "Created a chunk of size 12619, which is longer than the specified 1\n",
      "Created a chunk of size 9164, which is longer than the specified 1\n",
      "Created a chunk of size 7773, which is longer than the specified 1\n",
      "Created a chunk of size 5423, which is longer than the specified 1\n",
      "Created a chunk of size 10577, which is longer than the specified 1\n",
      "Created a chunk of size 5358, which is longer than the specified 1\n",
      "Created a chunk of size 5413, which is longer than the specified 1\n",
      "Created a chunk of size 17938, which is longer than the specified 1\n",
      "Created a chunk of size 31653, which is longer than the specified 1\n",
      "Created a chunk of size 7344, which is longer than the specified 1\n",
      "Created a chunk of size 89386, which is longer than the specified 1\n",
      "Created a chunk of size 48062, which is longer than the specified 1\n",
      "Created a chunk of size 103426, which is longer than the specified 1\n",
      "Created a chunk of size 21915, which is longer than the specified 1\n",
      "Created a chunk of size 13907, which is longer than the specified 1\n",
      "Created a chunk of size 17108, which is longer than the specified 1\n",
      "Created a chunk of size 9942, which is longer than the specified 1\n",
      "Created a chunk of size 19765, which is longer than the specified 1\n",
      "Created a chunk of size 22238, which is longer than the specified 1\n",
      "Created a chunk of size 15154, which is longer than the specified 1\n",
      "Created a chunk of size 15483, which is longer than the specified 1\n",
      "Created a chunk of size 3344, which is longer than the specified 1\n",
      "Created a chunk of size 20567, which is longer than the specified 1\n",
      "Created a chunk of size 16324, which is longer than the specified 1\n",
      "Created a chunk of size 8747, which is longer than the specified 1\n",
      "Created a chunk of size 40423, which is longer than the specified 1\n",
      "Created a chunk of size 3717, which is longer than the specified 1\n",
      "Created a chunk of size 26670, which is longer than the specified 1\n",
      "Created a chunk of size 25437, which is longer than the specified 1\n",
      "Created a chunk of size 10054, which is longer than the specified 1\n",
      "Created a chunk of size 8076, which is longer than the specified 1\n",
      "Created a chunk of size 19757, which is longer than the specified 1\n",
      "Created a chunk of size 9689, which is longer than the specified 1\n",
      "Created a chunk of size 9232, which is longer than the specified 1\n",
      "Created a chunk of size 7049, which is longer than the specified 1\n",
      "Created a chunk of size 8107, which is longer than the specified 1\n",
      "Created a chunk of size 16030, which is longer than the specified 1\n",
      "Created a chunk of size 4309, which is longer than the specified 1\n",
      "Created a chunk of size 5550, which is longer than the specified 1\n",
      "Created a chunk of size 15914, which is longer than the specified 1\n",
      "Created a chunk of size 14995, which is longer than the specified 1\n",
      "Created a chunk of size 5660, which is longer than the specified 1\n",
      "Created a chunk of size 14440, which is longer than the specified 1\n",
      "Created a chunk of size 7688, which is longer than the specified 1\n",
      "Created a chunk of size 13452, which is longer than the specified 1\n",
      "Created a chunk of size 3875, which is longer than the specified 1\n",
      "Created a chunk of size 12158, which is longer than the specified 1\n",
      "Created a chunk of size 20575, which is longer than the specified 1\n",
      "Created a chunk of size 16132, which is longer than the specified 1\n",
      "Created a chunk of size 10174, which is longer than the specified 1\n",
      "Created a chunk of size 6922, which is longer than the specified 1\n",
      "Created a chunk of size 1317, which is longer than the specified 1\n",
      "Created a chunk of size 2259, which is longer than the specified 1\n",
      "Created a chunk of size 7626, which is longer than the specified 1\n",
      "Created a chunk of size 18234, which is longer than the specified 1\n",
      "Created a chunk of size 23096, which is longer than the specified 1\n",
      "Created a chunk of size 19174, which is longer than the specified 1\n",
      "Created a chunk of size 24486, which is longer than the specified 1\n",
      "Created a chunk of size 5577, which is longer than the specified 1\n",
      "Created a chunk of size 8870, which is longer than the specified 1\n",
      "Created a chunk of size 87179, which is longer than the specified 1\n",
      "Created a chunk of size 16953, which is longer than the specified 1\n",
      "Created a chunk of size 30828, which is longer than the specified 1\n",
      "Created a chunk of size 27076, which is longer than the specified 1\n",
      "Created a chunk of size 12221, which is longer than the specified 1\n",
      "Created a chunk of size 1726, which is longer than the specified 1\n",
      "Created a chunk of size 92051, which is longer than the specified 1\n",
      "Created a chunk of size 27412, which is longer than the specified 1\n",
      "Created a chunk of size 75208, which is longer than the specified 1\n",
      "Created a chunk of size 15001, which is longer than the specified 1\n",
      "Created a chunk of size 19654, which is longer than the specified 1\n",
      "Created a chunk of size 59240, which is longer than the specified 1\n",
      "Created a chunk of size 18402, which is longer than the specified 1\n",
      "Created a chunk of size 62442, which is longer than the specified 1\n",
      "Created a chunk of size 4635, which is longer than the specified 1\n",
      "Created a chunk of size 7673, which is longer than the specified 1\n",
      "Created a chunk of size 102725, which is longer than the specified 1\n",
      "Created a chunk of size 28199, which is longer than the specified 1\n",
      "Created a chunk of size 49157, which is longer than the specified 1\n",
      "Created a chunk of size 48350, which is longer than the specified 1\n",
      "Created a chunk of size 8585, which is longer than the specified 1\n",
      "Created a chunk of size 2289, which is longer than the specified 1\n",
      "Created a chunk of size 89084, which is longer than the specified 1\n",
      "Created a chunk of size 51346, which is longer than the specified 1\n",
      "Created a chunk of size 30211, which is longer than the specified 1\n",
      "Created a chunk of size 11338, which is longer than the specified 1\n",
      "Created a chunk of size 95074, which is longer than the specified 1\n",
      "Created a chunk of size 9591, which is longer than the specified 1\n",
      "Created a chunk of size 49592, which is longer than the specified 1\n",
      "Created a chunk of size 21982, which is longer than the specified 1\n",
      "Created a chunk of size 11195, which is longer than the specified 1\n",
      "Created a chunk of size 6909, which is longer than the specified 1\n",
      "Created a chunk of size 11560, which is longer than the specified 1\n",
      "Created a chunk of size 21672, which is longer than the specified 1\n",
      "Created a chunk of size 44771, which is longer than the specified 1\n",
      "Created a chunk of size 25629, which is longer than the specified 1\n",
      "Created a chunk of size 20727, which is longer than the specified 1\n",
      "Created a chunk of size 56518, which is longer than the specified 1\n",
      "Created a chunk of size 11802, which is longer than the specified 1\n",
      "Created a chunk of size 11561, which is longer than the specified 1\n",
      "Created a chunk of size 8598, which is longer than the specified 1\n",
      "Created a chunk of size 20925, which is longer than the specified 1\n",
      "Created a chunk of size 7256, which is longer than the specified 1\n",
      "Created a chunk of size 16616, which is longer than the specified 1\n",
      "Created a chunk of size 32497, which is longer than the specified 1\n",
      "Created a chunk of size 56140, which is longer than the specified 1\n",
      "Created a chunk of size 54881, which is longer than the specified 1\n",
      "Created a chunk of size 13386, which is longer than the specified 1\n",
      "Created a chunk of size 6301, which is longer than the specified 1\n",
      "Created a chunk of size 73905, which is longer than the specified 1\n",
      "Created a chunk of size 92262, which is longer than the specified 1\n",
      "Created a chunk of size 8439, which is longer than the specified 1\n",
      "Created a chunk of size 13504, which is longer than the specified 1\n",
      "Created a chunk of size 20293, which is longer than the specified 1\n",
      "Created a chunk of size 12988, which is longer than the specified 1\n",
      "Created a chunk of size 31996, which is longer than the specified 1\n",
      "Created a chunk of size 26052, which is longer than the specified 1\n",
      "Created a chunk of size 8116, which is longer than the specified 1\n",
      "Created a chunk of size 51874, which is longer than the specified 1\n",
      "Created a chunk of size 50290, which is longer than the specified 1\n",
      "Created a chunk of size 4974, which is longer than the specified 1\n",
      "Created a chunk of size 58631, which is longer than the specified 1\n",
      "Created a chunk of size 64808, which is longer than the specified 1\n",
      "Created a chunk of size 18518, which is longer than the specified 1\n",
      "Created a chunk of size 4150, which is longer than the specified 1\n"
     ]
    }
   ],
   "source": [
    "### 문서 분할\n",
    "\n",
    "# 필요없는 부분 법령명으로 replace\n",
    "law_data = law_data.replace(\"\"\"판례\n",
    "연혁\n",
    "위임행정규칙\n",
    "규제\n",
    "생활법령\n",
    "한눈보기\"\"\",\"\")\n",
    "\n",
    "# 분할할 방식 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\\n\",\n",
    "    chunk_size=1,           # 구분자 기준으로 바로 쪼개지도록 최소값 설정\n",
    "    chunk_overlap=0,        # 중복 없음\n",
    "    is_separator_regex=False # 일반 문자열로 취급\n",
    ")\n",
    "\n",
    "# 분할\n",
    "chunks = text_splitter.split_text(law_data)\n",
    "\n",
    "# vectorDB에 넣을 문서 리스트\n",
    "documents=[]\n",
    "\n",
    "# vectorDB에 넣을 형식으로 변환\n",
    "for chunk in chunks:\n",
    "    #문서의 법령을 제목으로 사용하기 위한 개행으로 split\n",
    "    law_name = chunk.splitlines()\n",
    "    \n",
    "    # vectorDB에 넣을 형식으로 변환\n",
    "    doc = Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\n",
    "            \"law_name\": law_name[0], \n",
    "            \"length\": len(chunk)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # vectorDB에 넣을 list에 변환한 문서 append\n",
    "    documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cee044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface login\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "login(os.getenv('HUGGINGFACE_API_KEY'))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6439eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65534039221048308108415cbe5c196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\models--woong0322--ko-legal-sbert-finetuned. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e32cf46f884ff985783010d345fe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/205 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ae0b291e124fc4a93347ed4db091dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9475829eaa274e23a733e849a82b13c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e936e075ceea420cb6ee4efe2524f61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b8adab8266400789a9c56368db4d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a049899a5b4a6687a46a94c1d85932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de2f246edae40368fc6d0b32dda2e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34870430153240dc88c36034b01832f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa690f2aaf0415a92388a5c69c7f768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495244118b144de5a0f8fc1be9c6aaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### VectorDB에 저장\n",
    "\n",
    "# 모델에 따라 달라질 코드(임베딩)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"woong0322/ko-legal-sbert-finetuned\",\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'normalize_embeddings': True} # 의미 기반 검색 최적화\n",
    ")\n",
    "\n",
    "# qdrant 연결\n",
    "url = \"http://localhost:6333\"\n",
    "client = QdrantClient(url=url)\n",
    "\n",
    "# 각 법령의 구분 키값\n",
    "ids = [\n",
    "    str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{doc.metadata['law_name']}_{i}\")) \n",
    "    for i, doc in enumerate(documents)\n",
    "]\n",
    "\n",
    "# DB명\n",
    "collection_name = \"B-TEAM\"\n",
    "\n",
    "# vectorDB에 저장\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    ids = ids,\n",
    "    url=url,\n",
    "    collection_name=collection_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a54a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f875a9110f7b48ca8359e4af51b4b23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_exaone.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- configuration_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47844aee54e846b393428cae8e776d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_exaone.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- modeling_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649aabd1890f40b389fb8628e398e289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca7891900c2462bb157c8c241cd7b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6ba4e3e2584a9a889af460db45224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e738945f6e4b76be94ceeb00a5ba01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f20cd82cfa04b37bb9f37a431292304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd530bd4b3d847bcb7f429210cc5ff76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "### RAG\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"woong0322/ko-legal-sbert-finetuned\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# vectorDB연결\n",
    "url = \"http://localhost:6333\"\n",
    "collection_name = \"B-TEAM\"\n",
    "\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    url=url,\n",
    ")\n",
    "\n",
    "# 질문에 대한 답은 가장 유사한 것 하나\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "#llm 모델 설정\n",
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"auto\",               \n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model_engine = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    "    do_sample=True,\n",
    "    return_full_text=False,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=model_engine)\n",
    "\n",
    "# 프롬프트 구성\n",
    "qa_system_prompt = \"\"\"너는 대한민국 사회복지사를 지원하는 법령 검색 전문 AI 도우미이다.\n",
    "\n",
    "**기본 규칙**\n",
    "답변은 항상 한국어로 한다.\n",
    "당신은 전문가 도우미로 제공된 [법령 정보] 데이터에 기반한 정보를 제공한다.\n",
    "질문이 불확실한 경우 한 번 더 질문하여 질문을 구체화 한다.\n",
    "정보가 부족하면 \"정보를 찾을 수 없다\"고 답한다.\n",
    "데이터에 없는 내용은 추측해 답하지 않는다.\n",
    "\n",
    "역할:\n",
    "- 사회복지 관련 법령(예: 사회복지사업법, 노인복지법, 아동복지법, 장애인복지법 등)을 근거 문서에 기반하여 정확하게 안내한다.\n",
    "- 사용자의 질문에 대해 관련 법 조항을 우선적으로 제시하고, 사회복지 실무 관점에서 이해하기 쉽게 설명한다.\n",
    "\n",
    "원칙:\n",
    "- 제공된 문서[법령 정보] 안의 정보만을 근거로 답변한다.\n",
    "- 문서에 없는 내용은 추측하지 말고 \"관련 근거를 찾을 수 없다\"고 답변한다.\n",
    "- 법률적 최종 판단이나 자문은 하지 않는다.\n",
    "- 항상 조항 번호와 법령명을 명시한다.\n",
    "\n",
    "\n",
    "**질문 처리 절차 **\n",
    "1. 질문에서 \"핵심단어\"를 인식한다.\n",
    "-\"핵심단어\"란 질문자가 알고 싶어하는 정보를 찾기 위한 keyword 다.\n",
    "-예시: \"사회복지법인 설립 조건을 알고 싶어\", \"사회복지법인을 만들려면 어떻게 해야하지?\" 등의 질문의 \"핵심단어\"는 \"사회복지법인\", \"설립 조건\", \"만들다\"이다.\n",
    "\n",
    "2. \"핵심단어\"를 기준으로 조회한 법령들 중에서 질문과 가장 유사한 법령을 찾는다.\n",
    "-필요한 경우 질문과 연관된 추가 조항도 검토하여 답변의 완성도를 높인다.\n",
    "-예시: \"사회복지법인 설립 조건을 알고 싶어\" -> 제16조(법인의 설립허가) 항목 이외에 17조(정관)등에 대한 내용까지 요약 정리.\n",
    "\n",
    "\n",
    "답변 형식:\n",
    "1. 물어본 질문에 대해 간결하게 답변할 것.\n",
    "2. 근거가 된 [법령정보]에 대해 3가지 이하로 첨부할 것. 최소한으로 덧붙인다.\n",
    "3. 주의사항 또는 한계 안내할 것.\n",
    "\n",
    "사용자 : (사용자의 질문 내용)\n",
    "모델 : (질문에 대해 대화하듯이 친절하게 설명)\n",
    "\n",
    "관련 조항\n",
    "1. 제O조(명칭) : 조항의 핵심 내용 \n",
    "2. 제O조(명칭) : 조항의 핵심 내용 \n",
    "3. 제O조(명칭) : 조항의 핵심 내용 \n",
    "\n",
    "주의사항 또는 한계\n",
    "이 답변은 법률 자문이 아니며, 구체적인 행정 해석이나 적용 여부는 관할 행정기관 또는 법률 전문가에게 확인해야 한다.\n",
    "\n",
    "[법령 정보]:\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# LCEL 체인\n",
    "def extract_content(docs):\n",
    "    return docs[0].page_content if docs else \"관련 법령 없음\"\n",
    "\n",
    "# LCEL 체인: 구조 변경 없이 그대로 사용\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": (lambda x: x[\"input\"]) | retriever | extract_content,\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"]\n",
    "    }\n",
    "    | qa_prompt \n",
    "    | llm  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a337ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 성능 평가 모델\n",
    "evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\") # 판사 LLM\n",
    "evaluator_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#실제 대화\n",
    "chat_history = []\n",
    "print(\"법률 상담을 시작합니다. (종료: exit)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\n나: \")\n",
    "    if user_input.lower() in [\"exit\", \"종료\"]: break\n",
    "\n",
    "    #성능 평가 텍스트\n",
    "    retrieved_docs = retriever.invoke(f\"query: {user_input}\")\n",
    "    contexts = [doc.page_content for doc in retrieved_docs]\n",
    "\n",
    "    # 체인 호출\n",
    "    response = rag_chain.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "    print(f\"{response}\")\n",
    "\n",
    "    #성능 평가\n",
    "    current_eval_data = {\n",
    "        \"user_input\": [user_input],\n",
    "        \"response\": [str(response)],\n",
    "        \"retrieved_contexts\": [contexts]\n",
    "    }\n",
    "    eval_dataset = Dataset.from_dict(current_eval_data)\n",
    "\n",
    "    score = evaluate(\n",
    "            dataset=eval_dataset,\n",
    "            metrics = [\n",
    "                Faithfulness(llm=evaluator_llm),\n",
    "                AnswerRelevancy(\n",
    "                    llm=evaluator_llm,\n",
    "                    embeddings=evaluator_embeddings\n",
    "                ),\n",
    "            ],\n",
    "            llm=evaluator_llm,\n",
    "            embeddings=evaluator_embeddings\n",
    "        )\n",
    "        \n",
    "        # 점수 출력\n",
    "    f_score = score[\"faithfulness\"]\n",
    "    ar_score = score[\"answer_relevancy\"]\n",
    "    print(f\"   [ 성능 점수] 충실도(Faithfulness): {f_score:.2f} | 관련성(Relevancy): {ar_score:.2f}\")\n",
    "\n",
    "    # 대화 기록 업데이트 (최근 3턴만 유지하여 CPU 부담 감소)\n",
    "    chat_history.extend([HumanMessage(content=user_input), AIMessage(content=response)])\n",
    "    chat_history = chat_history[-6:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
